/*
 * TeamCity Configuration –¥–ª—è Performance Testing
 * Kotlin DSL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è JetBrains TeamCity
 */

import jetbrains.buildServer.configs.kotlin.*
import jetbrains.buildServer.configs.kotlin.buildFeatures.perfmon
import jetbrains.buildServer.configs.kotlin.buildSteps.gradle
import jetbrains.buildServer.configs.kotlin.buildSteps.script
import jetbrains.buildServer.configs.kotlin.projectFeatures.buildReportTab
import jetbrains.buildServer.configs.kotlin.triggers.vcs
import jetbrains.buildServer.configs.kotlin.triggers.schedule

version = "2023.11"

project {
    description = "Kotlin Performance Testing Pipeline"

    buildType(KotlinJvmBenchmarks)
    buildType(AndroidPerformanceTests)
    buildType(JmhDeepAnalysis)
    buildType(PerformanceReportAggregator)

    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ç—á–µ—Ç–æ–≤
    features {
        buildReportTab {
            title = "Performance Report"
            startPage = "performance-report.html"
        }
    }

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
    params {
        param("performance.threshold.warning", "120")  // 20% –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ
        param("performance.threshold.error", "200")    // 100% –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ
        param("kotlin.version", "1.9.20")
        param("android.compileSdk", "34")
    }
}

object KotlinJvmBenchmarks : BuildType({
    name = "Kotlin JVM Benchmarks"
    description = "Kotlin multiplatform performance benchmarks (JVM, JS, Native)"

    artifactRules = """
        build/reports/benchmarks => benchmarks-jvm.zip
        build/libs => jars.zip
    """.trimIndent()

    vcs {
        root(DslContext.settingsRoot)
        cleanCheckout = true
    }

    steps {
        gradle {
            name = "Build Project"
            tasks = "clean build -x test"
            gradleParams = "--info --stacktrace"
        }

        gradle {
            name = "Run JVM Benchmarks"
            tasks = "jvmBenchmark"
            gradleParams = "--info --continue"
        }

        gradle {
            name = "Run JS Benchmarks"
            tasks = "jsBenchmark"
            gradleParams = "--info --continue"
            executionMode = BuildStep.ExecutionMode.RUN_ON_FAILURE
        }

        gradle {
            name = "Run Native Benchmarks"
            tasks = "nativeBenchmark"
            gradleParams = "--info --continue"
            conditions {
                equals("teamcity.agent.jvm.os.name", "Linux")
            }
            executionMode = BuildStep.ExecutionMode.RUN_ON_FAILURE
        }

        script {
            name = "Process Benchmark Results"
            scriptContent = """
                #!/bin/bash
                set -e

                echo "üìä Processing benchmark results..."

                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
                mkdir -p teamcity-reports

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JVM —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if [ -d "build/reports/benchmarks/main" ]; then
                    echo "Processing JVM benchmarks..."
                    cp -r build/reports/benchmarks/main/* teamcity-reports/
                    echo "##teamcity[publishArtifacts 'teamcity-reports => jvm-benchmarks.zip']"
                fi

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JS —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if [ -d "build/reports/benchmarks/js" ]; then
                    echo "Processing JS benchmarks..."
                    cp -r build/reports/benchmarks/js teamcity-reports/js-results
                    echo "##teamcity[publishArtifacts 'teamcity-reports/js-results => js-benchmarks.zip']"
                fi

                # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                echo "Generating summary statistics..."

                find teamcity-reports -name "*.json" -exec echo "Found benchmark result: {}" \;

                # TeamCity —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                if [ -f "teamcity-reports/jvm.json" ]; then
                    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –¥–ª—è TeamCity –º–µ—Ç—Ä–∏–∫
                    python3 -c "
                import json
                import sys

                try:
                    with open('teamcity-reports/jvm.json', 'r') as f:
                        data = json.load(f)

                    for result in data:
                        benchmark_name = result['benchmark'].replace('.', '_')
                        score = result['primaryMetric']['score']

                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ TeamCity
                        print(f'##teamcity[buildStatisticValue key=\'{benchmark_name}_score\' value=\'{score:.2f}\']')

                except Exception as e:
                    print(f'Error processing benchmark results: {e}')
                "
                fi

                echo "‚úÖ Benchmark results processed successfully"
            """.trimIndent()
        }
    }

    triggers {
        vcs {
            triggerRules = "+:root=*"
            branchFilter = "+:main +:develop +:feature/*"
        }
    }

    features {
        perfmon {
        }
    }

    requirements {
        moreThan("teamcity.agent.hardware.memorySizeMb", "4096")
    }

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    params {
        param("env.GRADLE_OPTS", "-Dorg.gradle.daemon=false -Xmx2g")
        param("java.version", "17")
    }
})

object AndroidPerformanceTests : BuildType({
    name = "Android Performance Tests"
    description = "Android Jetpack Benchmark microbenchmarks and macrobenchmarks"

    artifactRules = """
        benchmark/build/outputs => android-micro-benchmarks.zip
        macrobenchmark/build/outputs => android-macro-benchmarks.zip
        benchmark-traces => benchmark-traces.zip
    """.trimIndent()

    vcs {
        root(DslContext.settingsRoot)
        cleanCheckout = true
    }

    steps {
        gradle {
            name = "Build Android App"
            tasks = "assembleRelease assembleAndroidTest assembleBenchmark"
            gradleParams = "--info"
        }

        script {
            name = "Setup Android Environment"
            scriptContent = """
                #!/bin/bash
                echo "Setting up Android environment..."

                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–º—É–ª—è—Ç–æ—Ä–∞ –¥–ª—è CI
                export ANDROID_SDK_ROOT=${'$'}ANDROID_HOME
                export PATH=${'$'}PATH:${'$'}ANDROID_HOME/tools:${'$'}ANDROID_HOME/platform-tools

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ADB
                adb version

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
                adb devices

                echo "Android environment ready"
            """.trimIndent()
        }

        gradle {
            name = "Run Microbenchmarks"
            tasks = "benchmark:connectedAndroidTest"
            gradleParams = """
                --info
                -Pandroid.testInstrumentationRunnerArguments.androidx.benchmark.suppressErrors=EMULATOR,LOW-BATTERY,UNLOCKED
            """.trimIndent()
            executionMode = BuildStep.ExecutionMode.RUN_ON_FAILURE
        }

        gradle {
            name = "Run Macrobenchmarks"
            tasks = "macrobenchmark:connectedAndroidTest"
            gradleParams = """
                --info
                -Pandroid.testInstrumentationRunnerArguments.androidx.benchmark.suppressErrors=EMULATOR,LOW-BATTERY,UNLOCKED
            """.trimIndent()
            executionMode = BuildStep.ExecutionMode.RUN_ON_FAILURE
        }

        script {
            name = "Extract Benchmark Traces"
            scriptContent = """
                #!/bin/bash
                set -e

                echo "üì± Extracting Android benchmark traces..."

                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è trace —Ñ–∞–π–ª–æ–≤
                mkdir -p benchmark-traces

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
                if adb devices | grep -q "device${'$'}"; then
                    echo "Device found, extracting traces..."

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º trace —Ñ–∞–π–ª—ã
                    adb shell ls /sdcard/Android/media/*/additional_test_output/ || echo "No benchmark outputs found"

                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ñ–∞–π–ª—ã
                    adb pull /sdcard/Android/media/ benchmark-traces/ || echo "Could not pull benchmark files"

                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                    trace_count=${'$'}(find benchmark-traces -name "*.perfetto-trace" | wc -l)
                    json_count=${'$'}(find benchmark-traces -name "*.json" | wc -l)

                    echo "Extracted ${'$'}trace_count Perfetto traces and ${'$'}json_count JSON files"

                    # TeamCity —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    echo "##teamcity[buildStatisticValue key='android_perfetto_traces' value='${'$'}trace_count']"
                    echo "##teamcity[buildStatisticValue key='android_json_results' value='${'$'}json_count']"

                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
                    if [ ${'$'}trace_count -gt 0 ]; then
                        echo "Perfetto trace file sizes:"
                        find benchmark-traces -name "*.perfetto-trace" -exec du -h {} \;
                    fi
                else
                    echo "‚ùå No Android device connected - skipping trace extraction"
                    echo "##teamcity[buildStatisticValue key='android_device_available' value='0']"
                fi

                echo "‚úÖ Android benchmark trace extraction completed"
            """.trimIndent()
        }
    }

    triggers {
        vcs {
            triggerRules = "+:root=*"
            branchFilter = "+:main +:develop"
        }

        schedule {
            schedulingPolicy = daily {
                hour = 2
                minute = 30
            }
            branchFilter = "+:main"
            triggerBuild = always()
        }
    }

    requirements {
        moreThan("teamcity.agent.hardware.memorySizeMb", "8192")
        contains("teamcity.agent.name", "android")  // –¢–æ–ª—å–∫–æ –∞–≥–µ–Ω—Ç—ã —Å Android SDK
    }

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Android
    params {
        param("env.ANDROID_HOME", "/opt/android-sdk")
        param("android.emulator.avd", "TeamCity_API_29")
    }
})

object JmhDeepAnalysis : BuildType({
    name = "JMH Deep Analysis"
    description = "–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å JMH"

    artifactRules = """
        build/libs/jmh.jar => jmh-jar.zip
        jmh-results.json => jmh-results.zip
        jmh-report.html => jmh-report.zip
    """.trimIndent()

    vcs {
        root(DslContext.settingsRoot)
    }

    steps {
        gradle {
            name = "Build JMH JAR"
            tasks = "jmhJar"
            gradleParams = "--info"
        }

        script {
            name = "Run JMH Benchmarks"
            scriptContent = """
                #!/bin/bash
                set -e

                echo "‚ö° Running JMH deep performance analysis..."

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ JMH jar
                if [ ! -f "build/libs/jmh.jar" ]; then
                    echo "‚ùå JMH jar not found!"
                    exit 1
                fi

                # –ó–∞–ø—É—Å–∫ JMH —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
                java -jar build/libs/jmh.jar \
                    -wi 3 \
                    -i 5 \
                    -f 1 \
                    -r 1s \
                    -w 1s \
                    -rf json \
                    -rff jmh-results.json \
                    -v EXTRA

                echo "‚úÖ JMH benchmarks completed"

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                if [ -f "jmh-results.json" ]; then
                    echo "Processing JMH results..."

                    # –°–æ–∑–¥–∞–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–≥–æ –æ—Ç—á–µ—Ç–∞
                    python3 -c "
                import json
                import sys

                try:
                    with open('jmh-results.json', 'r') as f:
                        results = json.load(f)

                    print('JMH Benchmark Results Summary:')
                    print('=' * 50)

                    total_benchmarks = len(results)
                    print(f'Total benchmarks: {total_benchmarks}')

                    # TeamCity —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    print(f'##teamcity[buildStatisticValue key=\\\"jmh_total_benchmarks\\\" value=\\\"{total_benchmarks}\\\"]')

                    for result in results:
                        benchmark = result['benchmark']
                        score = result['primaryMetric']['score']
                        unit = result['primaryMetric']['scoreUnit']
                        error = result['primaryMetric']['scoreError']

                        print(f'{benchmark}: {score:.2f} ¬± {error:.2f} {unit}')

                        # TeamCity —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞
                        safe_name = benchmark.replace('.', '_').replace(':', '_')
                        print(f'##teamcity[buildStatisticValue key=\\\"jmh_{safe_name}_score\\\" value=\\\"{score:.2f}\\\"]')
                        print(f'##teamcity[buildStatisticValue key=\\\"jmh_{safe_name}_error\\\" value=\\\"{error:.2f}\\\"]')

                except Exception as e:
                    print(f'Error processing JMH results: {e}')
                    sys.exit(1)
                "

                    echo "JMH results processed successfully"
                else
                    echo "‚ùå No JMH results found"
                    exit 1
                fi
            """.trimIndent()
        }
    }

    triggers {
        vcs {
            triggerRules = "+:root=*"
            branchFilter = "+:main"
        }
    }

    requirements {
        moreThan("teamcity.agent.hardware.memorySizeMb", "4096")
        moreThan("teamcity.agent.hardware.cpuCount", "2")
    }

    params {
        param("env.JMH_OPTS", "-Xmx2g")
    }
})

object PerformanceReportAggregator : BuildType({
    name = "Performance Report Aggregator"
    description = "–°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º performance —Ç–µ—Å—Ç–∞–º"

    type = BuildTypeSettings.Type.COMPOSITE

    vcs {
        root(DslContext.settingsRoot)
        showDependenciesChanges = true
    }

    dependencies {
        dependency(KotlinJvmBenchmarks) {
            snapshot {
                onDependencyFailure = FailureAction.IGNORE
            }
            artifacts {
                buildRule = lastSuccessful()
                artifactRules = "benchmarks-jvm.zip => artifacts/"
            }
        }

        dependency(AndroidPerformanceTests) {
            snapshot {
                onDependencyFailure = FailureAction.IGNORE
            }
            artifacts {
                buildRule = lastSuccessful()
                artifactRules = """
                    android-micro-benchmarks.zip => artifacts/
                    android-macro-benchmarks.zip => artifacts/
                    benchmark-traces.zip => artifacts/
                """.trimIndent()
            }
        }

        dependency(JmhDeepAnalysis) {
            snapshot {
                onDependencyFailure = FailureAction.IGNORE
            }
            artifacts {
                buildRule = lastSuccessful()
                artifactRules = "jmh-results.zip => artifacts/"
            }
        }
    }

    steps {
        script {
            name = "Generate Performance Report"
            scriptContent = """
                #!/bin/bash
                set -e

                echo "üìä Generating comprehensive performance report..."

                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á–µ—Ç–∞
                mkdir -p performance-report

                # –°–æ–∑–¥–∞–µ–º HTML –æ—Ç—á–µ—Ç
                cat > performance-report/index.html << 'EOF'
                <!DOCTYPE html>
                <html>
                <head>
                    <title>Performance Test Report - Build %build.number%</title>
                    <meta charset="utf-8">
                    <style>
                        body { font-family: Arial, sans-serif; margin: 20px; }
                        .summary { background: #f5f5f5; padding: 15px; border-radius: 5px; }
                        .result { margin: 10px 0; padding: 10px; border-left: 4px solid #4CAF50; }
                        .warning { border-left-color: #FF9800; }
                        .error { border-left-color: #F44336; }
                        table { width: 100%; border-collapse: collapse; margin: 15px 0; }
                        th, td { padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }
                        th { background-color: #f2f2f2; }
                    </style>
                </head>
                <body>
                    <h1>üöÄ Performance Test Report</h1>

                    <div class="summary">
                        <h2>Build Information</h2>
                        <ul>
                            <li><strong>Build Number:</strong> %build.number%</li>
                            <li><strong>Build VCS Number:</strong> %build.vcs.number%</li>
                            <li><strong>Agent:</strong> %agent.name%</li>
                            <li><strong>Date:</strong> %teamcity.build.start.date%</li>
                        </ul>
                    </div>

                    <h2>üìã Test Results Summary</h2>
                    <table>
                        <tr><th>Test Suite</th><th>Status</th><th>Artifacts</th></tr>
                EOF

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Ç—á–µ—Ç
                if [ -d "artifacts" ]; then
                    for artifact in artifacts/*.zip; do
                        if [ -f "$artifact" ]; then
                            basename=$(basename "$artifact" .zip)
                            echo "<tr><td>$basename</td><td>‚úÖ Completed</td><td><a href=\"../artifacts/$basename.zip\">Download</a></td></tr>" >> performance-report/index.html
                        fi
                    done
                else
                    echo "<tr><td colspan=\"3\">‚ùå No artifacts found</td></tr>" >> performance-report/index.html
                fi

                cat >> performance-report/index.html << 'EOF'
                    </table>

                    <h2>üéØ Next Steps</h2>
                    <ol>
                        <li>Download and analyze benchmark artifacts</li>
                        <li>Compare results with previous builds</li>
                        <li>Investigate any performance regressions</li>
                        <li>Update baseline performance metrics if needed</li>
                    </ol>

                    <p><small>Report generated automatically by TeamCity Performance Pipeline</small></p>
                </body>
                </html>
                EOF

                echo "‚úÖ Performance report generated successfully"
                echo "##teamcity[publishArtifacts 'performance-report => performance-report.zip']"
            """.trimIndent()
        }
    }

    triggers {
        finishBuildTrigger {
            buildType = "${KotlinJvmBenchmarks.id}"
            successfulOnly = false
        }
        finishBuildTrigger {
            buildType = "${AndroidPerformanceTests.id}"
            successfulOnly = false
        }
        finishBuildTrigger {
            buildType = "${JmhDeepAnalysis.id}"
            successfulOnly = false
        }
    }

    artifactRules = "performance-report.zip"
}

// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è TeamCity

// –®–∞–±–ª–æ–Ω –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
template {
    name = "Benchmark Template"

    params {
        param("benchmark.warmup.iterations", "3")
        param("benchmark.measurement.iterations", "5")
        param("benchmark.forks", "1")
    }

    steps {
        script {
            name = "Performance Check"
            scriptContent = """
                echo "Checking performance baseline..."
                # –ó–¥–µ—Å—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å baseline
            """.trimIndent()
        }
    }
}